출처: https://maclab-kaist.github.io/DeepArt/

#
numpy: 수치 자료를 고속으로 다루기 위한 라이브러리입니다.
librosa: 음원 파일을 분석하는 데 필요한 라이브러리입니다.
tensorflow: 인공신경망을 이용해 학습시키는 데 필요한 라이브러리입니다.
scikit-learn: tSNE를 이용해 자료를 2차원에 시각화하는데 필요한 라이브러리입니다.


# The NSynth Dataset split
- Train: 모델을 학습시킬 때 사용하는 부분입니다.
- Valid: 최적의 조건을 찾기 위해 여러 조건에서 모델을 학습하게 되는데,
         이 때 이 부분을 이용해 각 모델의 성능을 비교합니다.
- Test: Valid를 이용해 찾은 최고의 모델을 최종적으로 테스트하는데 필요한 부분입니다.


# wav 파일명

bass_synthetic_035-025-030.wav
음원종류_생성방식_악기번호_높이_세기.wav


#
많은 경우에 음원 자체(raw wave)를 이용하는 것보다
스펙트럼과 같이 분석된 정보를 이용하는 것이 기계학습에
더 효율이 좋다고 알려져 있습니다.
이 연습에서는 매 스펙트럼마다 1024 개의 샘플(기록)을 사용하고,
다음 스펙트럼은 256 샘플만큼 뒤에서 다시 추출합니다.
즉, 모든 스펙트럼은 자신과 인접한 스펙트럼과 768개의 샘플을 공유하게 됩니다.

샘플링 레이트(samping rate)는 소리를 녹음할 때
얼마나 자주 기록하는지를 의미합니다.
 NSynth 데이터셋의 경우 16,000 Hz로 일초에 16,000번
 기록했다는 의미입니다. 전체 샘플 길이는 4초이니
 각 샘플은 총 16,000 * 4 = 64,000개의 샘플을 가지고 있습니다.

전체 64,000개의 샘플을 256개씩 넘어가면서
스펙트럼을 추출하기 때문에 방식에 따라 250개 내외의
스펙트럼이 나오게 됩니다.
여기서 사용한 librosa.stft의 경우 총 251개가 나옵니다.

sequence_length = 251
feature_dimension = 513
스펙트럼에 1024개의 샘플을 넣었기 때문에 결과로 나오는 한
스펙트럼은 513개의 값을 가집니다. 한 파일에서 STFT를 추출하면
 (251, 513)의 크기를 가진 행렬이 나오게 됩니다.


#
‘train’ 셋의 경우 정규화(normalization)를 위해
평균(mean)과 표준편차(standard deviation, std)를 구해야 합니다.
정규화는 자료의 전체 혹은 일부의 평균과 표준편차를
일정한 값으로 조정해 주는 것으로 일반적으로 평균은 0으로,
표준편차는 1로 변환해줍니다.
 자료가 정규화되면 학습에 사용하는
 다양한 함수들이 더 효과적인 범위에서 작동하게 됩니다.

모든 자료를 동시에 로드할 수 있다면 numpy.mean(), numpy.std()
함수를 통해 간단히 평균과 표준편차를 구할 수 있지만
이 경우는 자료가 매우 크므로 직접 통계적인 계산을 해야 합니다.

평균은 전체 데이터의 합 / 전체 데이터의 수로 구할 수 있고,
표준편차는 (전체 데이터의 제곱의 평균 - 전체 데이터의 평균의 제곱)의 제곱근
으로 구할 수 있습니다.
전체 데이터의 수는 이미 알고 있으므로
합과 제곱의 합을 저장할 변수를 만들어 줍니다.


#
사람이 소리의 크기를 인지할 때,
소리의 크기가 커질수록 크기에 대한 민감도가 낮아집니다.
이를 좀 더 자세히 설명하면, 소리가 작을 때에는 에너지가
조금만 증가해도 소리가 커졌다고 인식하지만 소리가
클 때에는 에너지가 훨씬 더 많이 증가해야 소리가
비슷한만큼 커졌다고 인식하게 됩니다.
이를 수학적으로 로그함수(logarithm)으로 나타낼 수 있습니다.
이에 따라 log함수를 이용해 스펙트럼의 세기를 변환해주는 것이 좋습니다.


# 모델의 각 레이어와 레이어별 출력 사이즈

input: (sequence_length * spectrum_size), 1
convolution1: (3 * spectrum_size), 64
maxpool1: (3 * 1)
convolution2: (3 * 1), 64
maxpool2: (3 * 1)
convolution3: (3 * 1), 128
maxpool3: (3 * 1)
convolution4: (3 * 1), 128
maxpool4: (3 * 1)
flatten: (n)
fc1: 256
fc2: 256
fc3: n_labels