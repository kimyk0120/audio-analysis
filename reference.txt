
# 분석 구조

전처리 == preprocessing
특징값 == feature
추출 == extraction
분류기 == classifier

data 수집 --> 음악,음성신호 입력 --> [전처리] --> [특징값 왕창 추출]
--> [중요한거 골라주셈] --> [분류기] --> 결과

ex) <예>
애기가 우는 소리 녹음파일 -->[전처리:애기가 응애응애 하는 구간만 잘라냄]
--> [특징값: MFCC] --> [분류기:로지스틱 분류기] --> 배고프다 vs 졸리다 판별


# 전처리

- 알고리즘에 넣기 전에 사용에 용이하도록 처리를 해주는 것
- VAD (voice activity detection:음성 탐지)를 쓴다든지,
  신호의 크기가 다들 비슷비슷하다면 단순히 프레임의 평균/최대 진폭을 비교한다.
  후자의 경우 오디오 편집 툴에서 [노이즈 게이트]를 활용하면 된다.
- SNR확보: 신호의 잡음을 줄여준다.
  EQ, 필터: 신호가 존재할 수 있는 주파수 대역을 증폭시키거나
  반대로 없는 부분을 자름.
- 볼륨 정규화: 오디오 신호의 진폭(amplitude)를 최대값 ([-1, 1])로 키워줘서
  디지털 신호에 할당된 비트수를 최대한 활용하도록 한다
- Normalization
     '''
          import numpy as np
          import librosa
          x = librosa.core('event1.mp3', sr=None, mono=True)
          x = x / np.max(np.abs(x))
     '''
- Whitening (데이터의 분포를 평균을 0, 표준편차를 1로 맞춰준다)
- PCA - Principle Component Analysis를 써서 고차원 데이터를 압축
- Trimming
    앞뒤에 조용한 구간이 있다면 싹둑 잘라주는편이 좋겠죠.
    이건 어느정도 대애충 감으로 하는게 편할것같네요.
    저라면, hann window같은걸 씌우고,
    각 윈도에서 평균 에너지를 구해서 (np.mean(np.abs(windowed_source_x) ** 2)),
    그 윈도 별 평균 에너지를 기준으로,아무런 음향 이벤트가 안일어나는 첫 N개의 윈도와 마지막 M개의 윈도를 날리겠습니다
- Augmentation
    데이터가 부족하면 뻥튀기를 하고싶겠죠? 방법은 여러가지가 있습니다. 적당한 구간에서 pitch shift / time expanding을
    하시면 무난할테고, 다른 잡음을 적당히 섞어주는것도 좋겠죠 (x = x + gain * noise).


# 특징값 추출 (feature extraction)

- MFCC
    - MFCC는 이 배음 구조의 차이를 표현하는 숫자
    - 음정 (음고, pitch)이 변해도 MFCC가 (나름대로) 일정하게 유지
    - 음성 인식, 음악의 장르 분석, 감정 인식 등 다양한 분야에서 MFCC를 활용
- spectral centroid
- spectral rolloff
- zero-crossing
- spectral flux
- energy



# sample rate ( 44100 Hz혹은 44.1KHz )
- 초당 441000번으로 오디오 데이터를 샘플링
- 샘플링을 많이 할 수록 원음에 가까운 소리로 복원할 수 있다.
- 44.1KHz 는 CD 음질로 사용.


# frame
- 채널을 모두 합쳐서 하나의 샘플을 구성하고 있는 것
- 즉, 44100Hz 의 sample rate 으로 만들어진 오디오에는
  초당 44100개의 frame 이 포함되어 있으며, 모노인 경우에는 sample 의 개수가 frame 의
  개수와 동일하고,
- 스테레오인 경우에는 sample 의 개수가 88200개가 되는 것


# sample size
- 샘플 하나를 1 byte 로 표현할 것인가, 2 byte 로 표현할 것인가
- 1 byte로 표현하면, 하나의 샘플이 256 단계,
  2 byte로 표현하면 65536 단계로 나눠서 소리를 재현할 수 있으니,
  잘게 나눠 놓은 것이 더 원음의 가까운 소리를 낼 수 있다

# frame size
- 채널과 샘플 크기를 합쳐서 나타내는 말
- 예를 들어, 스테레오의 2 byte 샘플 크기로 표현되는 오디오의 frame size 는 2 * 2 = 4 byte 가 된다.


# 사운드란?

소리의 파형이 공기 중의 진동으로 우리 귀에 전달되어 들리는 것이며,
압력과 시간이라는 축으로 표시할 수 있습니다.
시간이 흐름에 따라 압력의 세기가 소리의 진동을 만들어 내는 것입니다.
오실로스코프로 소리를 보면 사람의 가청 주파수는 20~20000Hz라고 합니다.
이 말은 1초에 20번에서 2만 번의 징동수(주파수)를 갖는 소리를 사람이 들을 수 있다는 뜻입니다


# 비트란?

음악용 오디오 CD는 16Bit 44100Hz 스테레오라는 규격에 따르도록 되어 있습니다.
여기서 비트와 샘플 레이트를 만나게 되는데.
비트(Bit)라는 것은 음량의 폭을 가리킵니다.
16비트는 2의 16승으로 즉 6만 5536이라는 값을 가지게 됩니다.
볼륨을 6만 5536단계로 음을 표현한다는 것입니다.
8비트는 2의 8승이니까 256단계의 값을 가지게 된다는 것을 쉽게 알 수 있습니다.
또한 1비트는 6dB을 갖습니다.
그렇다면 16비트는 96dB을 갖겠죠(6×16=96).
이러한 것들로 인하여 음악인데도 용량이 작은 오디오 파일과 용량이
큰 오디오 파일이 존재하는데 음을 정밀하게 표시하게 하면 할수록
기하급수적으로 용량이 큰 오디오 파일로 형성됩니다.
또한 컴퓨터 프로세서나 CPU의 엄청난 계산속도도 필요해집니다.
아날로그가 아닌 디지털의 세계에서는 모두 이런 현상이 수반됩니다.
오디오 CD 는 16비트 인데 이것의 기준은 사람이 귀로 인식했을 때
가장 비트수가 작고 음질이 좋은 것을 기준으로 한 것입니다.
물론 32비트로 작업을 하면 계산상 음질은 좋겠지만 귀로 인식할 정도로 구분이 가지는 않습니다.
그것에 반해 데이터의 크기는 32비트가 16비트의 2배 용량이 됩니다.
16비트 스테레오로 녹음을 했을 때 1분당 약 10메가바이트를 사용하는데에 반해
32비트로 녹음을 하게 되면 배인 약 20메가바이트 정도가 사용 됩니다.
공간이 차지하는 정도에 비해 효과가 없다는 얘기 입니다.
하지만 공간도 충분하고 질좋은 소스라면 32비트 녹음도 권장할만 합니다.


# 샘플 레이트란?

샘플링 레이트(Sampling Rate)는 쉽게 말해 애니메이션 만화의 컷이라고 볼 수 있습니다.
애니메이션의 컷이 많을수록 움직임이 부드럽고 유연하고
반대로 몇장 그리지 않으면 딱딱하고 부자연스러운 것과 같이 샘플링 레이트가 높을수록 원음
복원 능력이 좋은 것입니다.
여기서 44100Hz라는 것은 1초에 44100번의 샘풀링을 했다는 것입니다.
디지털 오디오에서는 아날로그 신호의 두배를 샘풀링해야만 하나의 샘플을 가질 수 있습니다.
가청 주파수의 모든 범위를 샘플링 하려면 가청 주파수의 두 배를
샘플링해야 한다는 원리입니다(나이키스트의 정리).
가청 주파수가 20000Hz이므로 40000Hz로 샘플링하여야 한다는 것입니다.


# 양자화란?

아날로그 음을 디지털로 바꿀 때 시간 단위로 그 크기를 축정해
2진수로 바꾸는 것을 양자화(Quantization)라고 합니다.
양자화가 이루어지는 과정을 샘플링이라고 합니다.
아날로그 신호를 일정 간격으로 표본화하여 점을 부드럽게 이어서
그리면 원래의 소리처럼 재생할 수 있다는 것이죠.
막대기 하나하나의 간격이 샘플링 레이트가 됩니다.
이 막대가 조밀하면 조밀할수록 아날로그에 가까운 음으로 더 정확하게 기록
또는 재생할 수 있을 것임을 알 수 있습니다.


# 비트레이트?

샘플레이트는 정해진 비트의 규격 내에서 초당 샘플링 주기로 쪼개내는 횟수의 단위였다면,
비트레이트 는 정해진 비트와 샘플레이트 규격 내에서
초당 비트로 더해져서 처리되는 갯수의 단위

16 bit 44.1 kHz 규격의 비트레이트 (Kbps) 계산은
[2×16 bit×44.1 kHz＝1441.2 Kbps]


# FFmpeg

미디어 포맷 변환 라이브러리
Michael Niedermayer의 주도하에 개발되고 있는
모든 동영상, 음악, 사진 포맷들의 디코딩과 인코딩을 목표로 만들어지고 있는
 LGPL와 GPL 이중 라이센스[1]를 따르는 오픈소스 프로젝트.


# MFCC (Mel Frequency Cepstral Coefficient)

음성 인식에서 가장 널리 사용되는 알고리즘
음성 인식을 위하여 가장 먼저 해야할 것은
입력된 신호에서 노이즈 및 배경 소리로 부터 실제 유효한 소리의 특징을 추출하는 것이다.
MFCC는 바로 소리의 특징을 추출하는 기법인데,
입력된 소리 전체를 대상으로 하는 것이 아니라,
일정 구간(Short time)식 나누어, 이 구간에 대한 스펙트럼을 분석하여 특징을 추출하는 기법이다.

MFCC는 1980 대 Davis와 Mermelstein 에 의해 처음 소개 되었으며
지금까지도 MFCC에 기반한 많은 연구들이 나오고 있다.
MFCC 이전에는 HMM Classifier를 이용한 Linear Prediction Coefficients(LPC) 와
Linear Prediction Cepstral Coefficient(LPCC) 기법이 음성 인식 기법으로 주로 활용

...



# STFT (Short-Time Furier Transform)


# 교차검증

machine learning을 할때 사용자가 가지는 데이터는 오직 훈련집합(Training set) 과
테스트집합(Test set) 뿐이다.
집합내에 샘플의 수가 굉장히 많다면 물론 좋겠지만,
실제상황에서 샘플수가 무한정 제공 될 수는 없다.

따라서 데이터의 양이 충분치 않을 때,
분류기 성능측정의 통계적 신뢰도를 높이기 위해서 쓰는 방법이
재샘플링(resampling) 기법을 사용하는데
대표적인 방법으로는 k-fold cross validation 과 bootstrap가 있다.

총 개의 sample이 있다면 이 분류기의 성능은 어떻게 정의 할 수 있을 것인가?
샘플을 k로의 집단으로 나눈다(이때, 각 집단의 mean은 비슷할 수 있도록 나눈다)
분류기를 k-1개의 집합으로 학습을 시키고
나머지 1개의 집합으로 test하여 분류기의 성능을 측정한다.

이 과정을 서로다른 k번 수행 하고
획득한 k번의 정확도를 평균하여 그것을 분류기의 성능으로 정의할 수 있다.

극단적으로, K=N으로 하여, 샘플의 숫자만큼
반복 측정을 하는것을 하나 남기기(leave-one-out) 또는 잭나이프(jackknife)기법이라고 한다.
leave one out방법에서는 1개의 샘플로 테스트를 반복해서 하는 것이다.

교차검증의 장점은 가지고있는
샘플의 대부분을 training에 쓸수 있다는 것
k가 N에 가까워 질 수록  그만큼 시간이 많이 걸린다.


# VAD (voice activity detection:음성 탐지)


# PCA - Principle Component Analysis (주성분분석)

# 스펙트럼

스펙트럼은 어떤 신호를 소리의 높이에 따라 분해했을 때,
각 높이에 해당하는 성분이 얼마나 강한지 나타냅니다.
이 때, 신호의 높이를 주파수라고 하고,
낮은 소리는 낮은 주파수 성분이 강하게,
높은 소리는 높은 주파수의 성분이 강하게 나옵니다.
이를 통해 어떤 소리의 특징을 보다 알기 쉽게 표현할 수 있습니다.
스펙트럼을 짧은 시간마다 반복해서 추출한 것을
STFT(short-time Fourier transform)이라고 합니다.
많은 경우에 음원 자체(raw wave)를 이용하는 것보다 스펙트럼과 같이
분석된 정보를 이용하는 것이 기계학습에 더 효율이 좋다고 알려져 있습니다.


# t-SNE ( 고차원 데이터 시각화, Stochastic Neighbor Embedding)

- 차원축소(dimesionality reduction)
- 시각화(visualization)
- 고차원 데이터 x를 이웃 간의 거리를 보존하며 저차원의 y로 학습.
- 거리 정보(Euclidean distances)를 확률적으로 나타냄.
- 비선형 차원축소 기법 적용 시 다수의 관측치들이 겹쳐 보이는 문제.
- 기존의 SNE 경우 정규분포를 이용하여 유사도를 계산했지만,
  이를 방지하기 위해 T 분포를 사용.
- t-분포 확률적 임베딩(t-SNE)은 데이터의 차원 축소에 사용되는
  기계 학습 알고리즘 중 하나로, 제프리 힌튼에 의해 개발되었다.
  t-SNE는 비선형 차원 축소 기법으로,
  고차원 데이터를 특히 2, 3차원 등으로 줄여 가시화하는데에
  유용하게 사용된다.
  구체적으로 t-SNE는 비슷한 데이터는 근접한 2, 3차원의 지점으로,
  다른 데이터는 멀리 떨어진 지점으로 맵핑한다.
  t-SNE 알고리즘은 두 단계에 걸쳐서 진행된다.
  첫번째로, 각 데이터 쌍에 대해서 결합분포를 만든다.
  이 분포는 비슷한 데이터는 선택될 확률이 매우 높지만
  다른 데이터끼리는 선택될 확률이 매우 낮도록 설계된다.

